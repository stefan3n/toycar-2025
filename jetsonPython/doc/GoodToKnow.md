### [< back](./GuideForDocumentation.md)
# Arduino resets every time something connects to the serial.
# You need read/write rights for /dev/ttyUSBx and /dev/videoY. Just run ```sudo adduser USERNAME dialout``` and ```sudo adduser USERNAME video```
# If the Arduino is not mounted perfectly in the slot, it can produce problem with information given to pins, and even a short circuit (for short circuit you will hear a sound from Arduino).
# For whatever reasons, sometimes the cameras won't work. Just unplug the cameras and switch the usb ports around. This should fix some problems (select() timeout and some errors from opencv - all the errors should be printed in the log file)
# A good idea is to consider the orientation of the bounding box. The AI model can generate 2 types of bounding box: with AABB annotation or OBB annotation. The AABB annotation is a bounding box with edges parallel with the axis. The OBB orientation is a rotated bounding box that gives the orientation of the object. So if you need to know the object orientation, you better consider the OBB annotation. We chose AABB annotation, and we had some big problems when I needed to grab an object because I cannot determine the orientation of the object (I needed this to know how much to rotate the claw). To understand better the difference between them you can visit this [link](https://www.researchgate.net/figure/Bounding-volumes-sphere-axis-aligned-bounding-box-AABB-oriented-bounding-box_fig9_272093426).
# When you start this project it is very important the organization of the task. A good idea is to start with learning ROS (it works well with Jetson Nano), and at the same time start with the AI model (for us it worked on Jetson Orin Nano). And also it is a good idea to reuse pyserial from this project(it took about 2-3 weeks to make the serial communication work).
## Our lidar does only a 2D scan. Because of that the map it will create will contain only the obstacles that are at the same level (when I go with the car in the park the lidar doesn't see the curbs so the car sometimes hit them). To stop the robot from hiting object (as a table as example, becuse on cost map you only see the table's leg) we tried to put on the arm a distance sensor (HC-SR04), but it dint't work well. 
## If you want to use a sensor like HC-SR04, which needs real time processing do not connect directly to Jetson because it cannot do real time processing. But, Arduino is capable of real time processing so we connected the sensor to Arduino. It calculates the distance from the sensor based on a formula found on the internet on Arduino, and this value should be sent to Jetson. If you want to add information for obstacle avoidance in ROS, you should start a new node.